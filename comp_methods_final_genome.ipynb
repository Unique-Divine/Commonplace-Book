{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "comp_methods_final_genome.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1IibtJ5quvk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f0f1ea2-fbfc-4644-f0f7-00868cf69a4a"
      },
      "source": [
        "! pip install pytorch-lightning --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 675kB 5.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 829kB 8.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 17.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 7.8MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8itlPJ-YHDs"
      },
      "source": [
        "Run the following cell (uncommented) for TPU support"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4xY9gG9YFUT"
      },
      "source": [
        "# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\r\n",
        "# !python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KfRKjT3suBU"
      },
      "source": [
        "import os\r\n",
        "import torch\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns; sns.set()\r\n",
        "from numpy.lib.ufunclike import _deprecate_out_named_y\r\n",
        "# neural network packages\r\n",
        "import torch\r\n",
        "import torch.nn as nn \r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.utils.data\r\n",
        "import torch.optim\r\n",
        "import pytorch_lightning as pl \r\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "import sys\r\n",
        "import time\r\n",
        "import random\r\n",
        "from typing import List, Tuple, Dict, Any\r\n",
        "# sklearn\r\n",
        "from sklearn import feature_selection\r\n",
        "import sklearn.preprocessing\r\n",
        "import sklearn.metrics\r\n",
        "from sklearn import model_selection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlXJSsibtoiN",
        "outputId": "5702bc22-9075-436a-d605-d5f2aea04406"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "\"\"\"Running this cell will generate a message asking you \r\n",
        "to click on a link where you'll obtain an authorization code.\r\n",
        "\r\n",
        "Paste that authorization code into the text box that appears below.\r\n",
        "\"\"\"\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FkbA6ZEtsjE",
        "outputId": "750f0e29-5a54-4ea7-8a25-104e8c6bfa7a"
      },
      "source": [
        "!cd \"/content/gdrive/MyDrive/\" && ls # Displays directories in MyDrive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Analysis I Chapter 3'\t'Colab Notebooks'\t\t       Seminar\n",
            " Autodidacticism\t Data\t\t\t\t       Sonder\n",
            " Brain\t\t\t Philosophy-of-Cognitive-Science.pdf   speech_shared\n",
            " CML\t\t\t School\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97NZklcNtycp",
        "outputId": "0fd786c7-e183-47c9-c340-8883e2df2108"
      },
      "source": [
        "dir_path = os.path.join(\"/content/gdrive/MyDrive/Data\", \"NNsforGenomics\")\r\n",
        "os.path.exists(dir_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZJxjss5tACK"
      },
      "source": [
        "sys.path.append(dir_path)\r\n",
        "data_path = os.path.join(dir_path, \"data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmuKfJ-vukMr"
      },
      "source": [
        "import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qqcWJID3Fub"
      },
      "source": [
        "class TabularDataset(torch.utils.data.Dataset): # inherit from torch\r\n",
        "    def __init__(self, stage: str, X: np.ndarray, Y: np.ndarray):\r\n",
        "        assert stage in [\"train\", \"val\", \"test\"]\r\n",
        "        splits = np.array([70, 15, 15])\r\n",
        "        train_size, val_size, test_size = splits\r\n",
        "        # train-test split\r\n",
        "        train_test_splits = model_selection.train_test_split(\r\n",
        "            X, Y, test_size = test_size, random_state = 42)\r\n",
        "        X_train, X_test, Y_train, Y_test = train_test_splits\r\n",
        "        # train-val split\r\n",
        "        relative_val_size = val_size / (train_size + val_size)\r\n",
        "        train_val_splits = model_selection.train_test_split(\r\n",
        "            X_train, Y_train, test_size = relative_val_size,\r\n",
        "            random_state = 42)\r\n",
        "        X_train, X_val, Y_train, Y_val = train_val_splits\r\n",
        "\r\n",
        "        assert X_train.shape[0] + X_val.shape[0] + X_test.shape[0] == X.shape[0] \r\n",
        "\r\n",
        "        # data loading\r\n",
        "        if stage == \"train\":\r\n",
        "            X, Y = X_train, Y_train\r\n",
        "        elif stage == \"val\":\r\n",
        "            X, Y = X_val, Y_val\r\n",
        "        elif stage == \"test\": \r\n",
        "            X, Y = X_test, Y_test\r\n",
        "        else:\r\n",
        "            raise ValueError(\"Invalid argment for `stage`.\"\r\n",
        "                + \"`stage` must be 'train', 'val', or 'test'.\")\r\n",
        "        X, Y = [arr.astype(float) for arr in [X, Y]]\r\n",
        "        self.X = torch.from_numpy(X)\r\n",
        "        self.Y = torch.from_numpy(Y.reshape(-1,1))\r\n",
        "\r\n",
        "        self.n_samples = X.shape[0]\r\n",
        "        if self.X.shape[0] != self.Y.shape[0]:\r\n",
        "            raise ValueError(\"Shape mismatch. X and Y should have the same \" \r\n",
        "                + \"number of rows\")\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        return self.X[idx], self.Y[idx]\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        return self.n_samples\r\n",
        "\r\n",
        "class LitFFNN(pl.LightningModule):\r\n",
        "    # ----------------------------------\r\n",
        "    # Initialize constants and NN architecture\r\n",
        "    # ----------------------------------\r\n",
        "    def __init__(self, X: np.ndarray, Y: np.ndarray, \r\n",
        "                 data_dir: str = os.getcwd()):\r\n",
        "        \"\"\" Feed-Forward Neural Network System\r\n",
        "        Args:\r\n",
        "            X (np.ndarray): Feature matrix \r\n",
        "            Y (np.ndarray): Target matrix\r\n",
        "        \"\"\"\r\n",
        "        super().__init__()\r\n",
        "        # TODO: train-val-test splits\r\n",
        "        self.X, self.Y = X, Y\r\n",
        "        self.n_features = self.X.shape[1]\r\n",
        "\r\n",
        "        # Hard-coded constants\r\n",
        "        self.loss_fn = nn.NLLLoss()\r\n",
        "        \r\n",
        "        self.lr = 1e-2\r\n",
        "        self.BATCH_SIZE = 16\r\n",
        "        self.N_CLASSES = 3\r\n",
        "        \r\n",
        "        self.epoch = 0\r\n",
        "        self.prog_bar = True\r\n",
        "        # ----------------------------------\r\n",
        "        # Architecture\r\n",
        "        # ----------------------------------\r\n",
        "        self.D_IN = self.X.shape[1]\r\n",
        "        D_h_in = int((2 / 3) * self.D_IN)\r\n",
        "        D_h_out = int((1 / 3) * self.D_IN)\r\n",
        "\r\n",
        "        '''\r\n",
        "        self.fc_layers = nn.Sequential(\r\n",
        "            nn.Linear(self.D_IN, D_h_in),\r\n",
        "                nn.LeakyReLU(),\r\n",
        "                nn.Dropout(p = 0.2),\r\n",
        "            nn.Linear(D_h_in, D_h_out),\r\n",
        "                nn.LeakyReLU(),\r\n",
        "                nn.Dropout(p = 0.4),\r\n",
        "            nn.Linear(D_h_out, self.N_CLASSES)\r\n",
        "        )\r\n",
        "        '''\r\n",
        "        self.fc_layers = nn.Sequential(\r\n",
        "            nn.Linear(self.D_IN, 10),\r\n",
        "                nn.LeakyReLU(),\r\n",
        "                #nn.Dropout(p = 0.0),\r\n",
        "            nn.Linear(10, self.N_CLASSES)\r\n",
        "            )\r\n",
        "\r\n",
        "        self.epoch_train_losses = []\r\n",
        "        self.epoch_val_losses = []\r\n",
        "        self.best_val_loss = np.infty\r\n",
        "        self.best_val_epoch = 0\r\n",
        "\r\n",
        "    def forward(self, x): \r\n",
        "            x = x.float()\r\n",
        "            x = self.fc_layers(x)\r\n",
        "            logits = F.log_softmax(input = x, dim = 1)\r\n",
        "            return logits\r\n",
        "\r\n",
        "    def configure_optimizers(self):\r\n",
        "        optimizer = torch.optim.Adam(\r\n",
        "            params = self.parameters(), lr = self.lr)\r\n",
        "        return optimizer\r\n",
        "\r\n",
        "    # ----------------------------------\r\n",
        "    # Training, validation, and test steps\r\n",
        "    # ----------------------------------\r\n",
        "\r\n",
        "    def training_step(self, batch, batch_idx):\r\n",
        "        x, y = batch\r\n",
        "        y = y.flatten().long()\r\n",
        "        logits = self(x) \r\n",
        "        loss = self.loss_fn(logits, y)\r\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, \r\n",
        "                 prog_bar=self.prog_bar)\r\n",
        "        return loss\r\n",
        "\r\n",
        "    def validation_step(self, batch, batch_idx, val=True):\r\n",
        "        x, y = batch\r\n",
        "        y = y.flatten().long()\r\n",
        "        # compute loss\r\n",
        "        logits = self(x)\r\n",
        "        loss = self.loss_fn(logits, y)\r\n",
        "        # compute accuracy\r\n",
        "        y_hat = self.predict(x)\r\n",
        "        accuracy = self.accuracy(y_hat, y)\r\n",
        "        # self.log interacts with TensorBoard\r\n",
        "        self.log('val_loss', loss, on_step=True, on_epoch=True, \r\n",
        "                 prog_bar=self.prog_bar)\r\n",
        "        self.log('val_acc', accuracy, on_step=False, on_epoch=True, \r\n",
        "            prog_bar=self.prog_bar)\r\n",
        "        return loss\r\n",
        "\r\n",
        "    def test_step(self, batch, batch_idx):\r\n",
        "        return self.validation_step(batch, batch_idx, val = False)\r\n",
        "\r\n",
        "    def training_epoch_end(self, outputs: List[Any]):\r\n",
        "        # self.epoch_train_loss = np.array(outputs).mean()\r\n",
        "        outputs: List[torch.Tensor] = [list(d.values())[0] for d in outputs]\r\n",
        "        sum = torch.zeros(1, dtype=float).to(self.device)\r\n",
        "        for batch_idx, batch_loss in enumerate(outputs):\r\n",
        "            sum += batch_loss.to(self.device)\r\n",
        "        avg_batch_loss = (sum / batch_idx)\r\n",
        "        self.epoch_train_losses.append({avg_batch_loss[0].item()})\r\n",
        "\r\n",
        "    def validation_epoch_end(self, outputs: List[Any]):\r\n",
        "        sum = torch.zeros(1, dtype=float).to(self.device)\r\n",
        "        for batch_idx, batch_loss in enumerate(outputs):\r\n",
        "            sum += batch_loss.to(self.device)\r\n",
        "        avg_batch_loss = (sum / batch_idx) \r\n",
        "        self.epoch_val_losses.append({avg_batch_loss[0].item()})        \r\n",
        "\r\n",
        "    def predict(self, x):\r\n",
        "        self.eval()\r\n",
        "        x.to(self.device)\r\n",
        "        logits = self(x)\r\n",
        "        preds = torch.argmax(logits, dim=1)\r\n",
        "        return preds\r\n",
        "\r\n",
        "    def accuracy(self, y_hat, y):\r\n",
        "        return pl.metrics.functional.accuracy(y_hat, y)\r\n",
        "\r\n",
        "    # ----------------------------------\r\n",
        "    # Data preparation hooks\r\n",
        "    # ----------------------------------\r\n",
        "    def get_dataloader(self, stage: str):\r\n",
        "        if stage == \"train\":\r\n",
        "            dataset = TabularDataset(stage = \"train\", X = self.X, Y = self.Y)\r\n",
        "        if stage == \"val\":\r\n",
        "            dataset = TabularDataset(stage = \"val\", X = self.X, Y = self.Y)\r\n",
        "        if stage == \"test\":\r\n",
        "            dataset = TabularDataset(stage = \"test\", X = self.X, Y = self.Y)\r\n",
        "        dl = torch.utils.data.DataLoader(\r\n",
        "            dataset = dataset, batch_size = self.BATCH_SIZE) \r\n",
        "        return dl \r\n",
        "        \r\n",
        "    def train_dataloader(self) -> torch.utils.data.DataLoader:\r\n",
        "        return self.get_dataloader(\"train\")\r\n",
        "    def val_dataloader(self) -> torch.utils.data.DataLoader:\r\n",
        "        return self.get_dataloader(\"val\")\r\n",
        "    def test_dataloader(self) -> torch.utils.data.DataLoader:\r\n",
        "        return self.get_dataloader(\"test\")\r\n",
        "\r\n",
        "    def plot_losses(self, plot_train=True):\r\n",
        "        skip_frames = 1\r\n",
        "        fig, ax = plt.subplots()\r\n",
        "        fig.tight_layout()\r\n",
        "\r\n",
        "        n_epochs = len(self.epoch_val_losses)\r\n",
        "        self.epoch_train_losses = [s.pop() for s in self.epoch_train_losses]\r\n",
        "        self.epoch_val_losses = [s.pop() for s in self.epoch_val_losses]\r\n",
        "        if plot_train:\r\n",
        "            n_epochs = len(self.epoch_train_losses)\r\n",
        "            ax.plot(np.arange(n_epochs)[skip_frames:], \r\n",
        "                    self.epoch_train_losses[skip_frames:], label=\"train\")\r\n",
        "        ax.plot(np.arange(n_epochs)[skip_frames:], \r\n",
        "                self.epoch_val_losses[1:][skip_frames:], label=\"val\")\r\n",
        "        ax.set(xlabel=\"Epoch\", ylabel=\"Loss\")\r\n",
        "        ax.legend()\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "    def custom_train(self, n_epochs, plot=True, verbose=False, plot_train=False):\r\n",
        "        train_loader = self.train_dl\r\n",
        "        val_loader = self.test_dl\r\n",
        "        device=self.device\r\n",
        "        self.network.to(device)\r\n",
        "\r\n",
        "        train_losses, val_losses = [], []\r\n",
        "        best_val_loss = np.infty\r\n",
        "        best_val_epoch = 0\r\n",
        "        early_stopping_buffer = 10\r\n",
        "        epoch = 0\r\n",
        "        best_params = None\r\n",
        "        for epoch in range(n_epochs):\r\n",
        "            train_loss, val_loss = 0.0, 0.0\r\n",
        "  \r\n",
        "            # Training\r\n",
        "            self.network.train()\r\n",
        "            for idx, batch in enumerate(train_loader):\r\n",
        "                self.optimizer.zero_grad() # clears paramter gradient buffers\r\n",
        "                inputs, targets = batch\r\n",
        "                # transfer batch data to computation device\r\n",
        "                inputs, targets = [\r\n",
        "                    tensor.to(device) for tensor in [inputs, targets]]\r\n",
        "                targets = targets.long() # converts dtype to Long\r\n",
        "                output = self.network(inputs)\r\n",
        "                loss = self.loss_fn(output, targets.flatten())\r\n",
        "                # back propagation\r\n",
        "                loss.backward()\r\n",
        "                self.optimizer.step() # update model weights\r\n",
        "                train_loss += loss.data.item()\r\n",
        "                if (idx % 10 == 0) and verbose:\r\n",
        "                    print(f\"epoch {epoch+1}/{n_epochs}, batch {idx}.\")\r\n",
        "            train_loss = train_loss / len(train_loader)\r\n",
        "            train_losses.append(train_loss)\r\n",
        "           \r\n",
        "            # Validation \r\n",
        "            self.network.eval()        \r\n",
        "            for batch in val_loader:\r\n",
        "                inputs, targets = batch\r\n",
        "                inputs, targets = [tensor.to(device) for tensor in batch]\r\n",
        "                targets = targets.long() # converts dtype to Long\r\n",
        "                output = self.network(inputs)\r\n",
        "                loss = self.loss_fn(output, targets.flatten())\r\n",
        "                val_loss += loss.data.item()\r\n",
        "\r\n",
        "            val_loss = val_loss / len(val_loader)\r\n",
        "            val_losses.append(val_loss)\r\n",
        "\r\n",
        "            if val_loss < best_val_loss:\r\n",
        "              best_params = self.network.parameters()\r\n",
        "              best_val_loss = val_loss\r\n",
        "              best_val_epoch = epoch\r\n",
        "            \r\n",
        "            # If validation loss fails to decrease for some number of epochs\r\n",
        "            # end training\r\n",
        "            if np.abs(epoch - best_val_epoch) > early_stopping_buffer:\r\n",
        "              break\r\n",
        "        \r\n",
        "            print(f\"Epoch: {epoch}, Training Loss: {train_loss:.3f}, \"\r\n",
        "                 +f\"Validation loss: {val_loss:.3f}\")\r\n",
        "        \r\n",
        "        #self.network.parameters = best_params\r\n",
        "        self.best_val_loss = best_val_loss\r\n",
        "        self.best_val_epoch = best_val_epoch\r\n",
        "        if plot:\r\n",
        "            skip_frames = 3\r\n",
        "            fig, ax = plt.subplots()\r\n",
        "            fig.tight_layout()\r\n",
        "            if plot_train:\r\n",
        "              ax.plot(np.arange(epoch + 1)[skip_frames:], \r\n",
        "                      train_losses[skip_frames:], '-', label=\"training set\")\r\n",
        "            ax.plot(np.arange(epoch + 1)[skip_frames:], \r\n",
        "                    val_losses[skip_frames:], '-', label=\"test set\")\r\n",
        "            ax.set(xlabel=\"Epoch\", ylabel=\"Loss\")\r\n",
        "            ax.legend()\r\n",
        "            plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvRfSxOFrtWQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f2zP9TFs9zV"
      },
      "source": [
        "```python\r\n",
        "# temporarily commented out\r\n",
        "def predict(input: np.ndarray, ffnn: nn.Module) -> np.ndarray:\r\n",
        "    input = torch.Tensor(input).to(ffnn.device)\r\n",
        "    output = ffnn.network(input).cpu().detach().numpy().argmax(axis = 1)\r\n",
        "    return output\r\n",
        "def accuracy(Y: np.ndarray, Y_pred: np.ndarray) -> float:\r\n",
        "    Y_pred, Y = [y.flatten() for y in [Y_pred, Y]]\r\n",
        "    right, wrong = pd.Series(Y_pred == Y).value_counts()\r\n",
        "    return right / (right + wrong)\r\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvuKBC4JtVVd",
        "outputId": "db5d8e12-7e3c-493d-b37f-6a2aa5f64139"
      },
      "source": [
        "# Retrieve target variables\r\n",
        "pp = preprocessing.Preprocessing()\r\n",
        "Y, names = pp.get_Y(data_path=data_path)\r\n",
        "Y, names = [arr.flatten() for arr in [Y, names]]\r\n",
        "Y.shape, names.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4061,), (4061,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT8awj-gyZFi"
      },
      "source": [
        "def indices_found(n: int, skip: list, s: int) -> np.ndarray:\r\n",
        "    assert n - np.array(skip).size == s\r\n",
        "    all = np.arange(n)\r\n",
        "    return np.array(list(set(all).difference(set(skip))))\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwKoM8qxm6Ju"
      },
      "source": [
        "import random\n",
        "'''\n",
        "def sample_from_data(num_samples=1000):\n",
        "  print('--------------SAMPLING-------------------')\n",
        "  filename = os.path.join(data_path, \"C/gt_C.csv\")\n",
        "  n = sum(1 for line in open(filename)) - 1 #number of records in file (excludes header)\n",
        "  s = num_samples #desired sample size\n",
        "  skip = sorted(random.sample(range(1,n+1),n-s)) #the 0-indexed header will not be included in the skip list\n",
        "  A = pd.read_csv(filename, skiprows=skip).values[:, 1:].T\n",
        "  indices = indices_found(n, skip, s)\n",
        "  print('---------------------------')\n",
        "\n",
        "  return A, indices\n",
        "'''\n",
        "\n",
        "def sample_from_data(num_samples=1000):\n",
        "  np.random.seed()\n",
        "  idx = np.random.choice(X.shape[1], num_samples, replace=False)\n",
        "  return X[:, idx], idx\n",
        "\n",
        "def sample_from_indices(indices):\n",
        "  return X[:, indices], indices\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZxfpL2Z3zZ-P",
        "outputId": "48897a2f-ce41-4b5b-c49e-75bf784f3cf7"
      },
      "source": [
        "'''\n",
        "filename = os.path.join(data_path, \"X.csv\")\n",
        "X = pd.read_csv(filename).values\n",
        "print(\"X: \", X.shape)\n",
        "np.save(os.path.join('./X.npy'), X)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfilename = os.path.join(data_path, \"X.csv\")\\nX = pd.read_csv(filename).values\\nprint(\"X: \", X.shape)\\nnp.save(os.path.join(\\'./X.npy\\'), X)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6JGGdImqMaQ"
      },
      "source": [
        "X = np.load(os.path.join(data_path, 'X.npy'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqy9CiqPtIH4"
      },
      "source": [
        "# ckpt\r\n",
        "import logging\r\n",
        "import torch.multiprocessing as mp\r\n",
        "from torch.multiprocessing import Manager\r\n",
        "import time\r\n",
        "#mp.set_start_method('spawn')# good solution !!!!\r\n",
        "\r\n",
        "logging.getLogger('lightning').setLevel(0)\r\n",
        "\r\n",
        "early_stop_callback = EarlyStopping(\r\n",
        "   monitor='val_acc',\r\n",
        "   min_delta=0.00,\r\n",
        "   patience=1,\r\n",
        "   verbose=False,\r\n",
        "   mode='max'\r\n",
        ")\r\n",
        "\r\n",
        "def train_model(accuracies, indices, rank, n_feat=100, use_indices=None):\r\n",
        "  #accuracies = list(accuracies)\r\n",
        "  #indices = list(indices)\r\n",
        "  start_time = time.time()\r\n",
        "  if use_indices is None:\r\n",
        "    A, index = sample_from_data(n_feat)\r\n",
        "  else:\r\n",
        "    assert use_indices.shape[-1] == n_feat\r\n",
        "    A, index = sample_from_indices(use_indices)\r\n",
        "  model = LitFFNN(X = A, Y = Y,\r\n",
        "      data_dir = os.path.join(data_path, \"temp\"))\r\n",
        "  trainer = pl.Trainer(gpus = 0, max_epochs=10,\r\n",
        "      progress_bar_refresh_rate=0, weights_summary=None,\r\n",
        "      callbacks=[early_stop_callback], num_sanity_val_steps=0)\r\n",
        "  trainer.fit(model)\r\n",
        "  acc = model.accuracy(\r\n",
        "    y_hat = model.predict(torch.Tensor(A.astype(float))),\r\n",
        "    y = torch.Tensor(Y.astype(float))).item()\r\n",
        "  \r\n",
        "  if isinstance(accuracies, np.ndarray):\r\n",
        "    np.append(accuracies, acc)\r\n",
        "    np.append(indices, index)\r\n",
        "  else:\r\n",
        "    accuracies.append(acc)\r\n",
        "    indices.append(index)\r\n",
        "\r\n",
        "  return model, accuracies, indices\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Evf4Ms7qlVX"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train_initial_population(num_pop=100, num_proc=10, n_feat=100):\n",
        "  print('Training initial population')\n",
        "  assert num_pop % num_proc == 0\n",
        "  with Manager() as manager:\n",
        "    accuracies = manager.list()  # <-- can be shared between processes.\n",
        "    indices = manager.list()  # <-- can be shared between processes.\n",
        "    processes = []\n",
        "    num_loops = num_pop // num_proc \n",
        "    for i in tqdm(range(num_loops)):\n",
        "      for rank in range(num_proc):\n",
        "        p = mp.Process(target=train_model, args=(accuracies, indices, rank, n_feat))\n",
        "        p.start()\n",
        "        processes.append(p)\n",
        "      for p in processes:\n",
        "        p.join()\n",
        "    accuracies = list(accuracies)\n",
        "    indices = list(indices)\n",
        "    return np.asarray(accuracies), np.asarray(indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKyZJMSItqRa"
      },
      "source": [
        "def mutate(accuracies, indices, frac_to_kill=0.2, mutate_freq=0.1):\n",
        "  n_to_kill = int(len(accuracies) * frac_to_kill)\n",
        "  # Select lowest performing by sortin\n",
        "  \n",
        "  acc_sort_idx = accuracies.argsort()\n",
        "  sorted_indices = indices[acc_sort_idx[::-1]]\n",
        "  sorted_accuracies = accuracies[acc_sort_idx[::-1]]\n",
        "  indices_to_mutate = sorted_indices[:n_to_kill, :]\n",
        "  # Get binary vectors determining which features to mutate\n",
        "  mutate_features = np.random.binomial(1, p=mutate_freq, size=indices_to_mutate.shape)\n",
        "  mutated_indices = np.empty(indices_to_mutate.shape)\n",
        "  # Sample new data:\n",
        "  for model_idx in range(indices_to_mutate.shape[0]):\n",
        "    _, random_idx = sample_from_data(indices.shape[-1])\n",
        "    # indices_to_mutate[model_idx, :] * mutated_indices selects the indices to be mutated\n",
        "    # indices_to_mutate[model_idx, :] * (1 - mutated_indices) selects the indices to be kept\n",
        "    mutated_indices[model_idx, :] = random_idx * mutate_features[model_idx, :] + ((1 - mutate_features[model_idx, :]) * indices_to_mutate[model_idx, :])\n",
        "  \n",
        "  # Remove least fit individuals\n",
        "  accuracies = sorted_accuracies[:-n_to_kill]\n",
        "  indices = sorted_indices[:-n_to_kill]\n",
        "  return accuracies, indices, mutated_indices.astype(np.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmnMIsuAdBvH"
      },
      "source": [
        "def train_mutations(mutate_indices, accuracies=[], indices=[], num_proc=10):\n",
        "  with Manager() as manager:\n",
        "    accuracies = manager.list(accuracies)  # <-- can be shared between processes.\n",
        "    indices = manager.list(indices)  # <-- can be shared between processes.\n",
        "    processes = []\n",
        "    num_pop = mutate_indices.shape[0]\n",
        "    n_feat = mutate_indices.shape[1]\n",
        "    num_loops = num_pop // num_proc \n",
        "    if num_loops == 0:\n",
        "      num_loops += 1\n",
        "    counter = 0\n",
        "    for i in tqdm(range(num_loops)):\n",
        "      for rank in range(num_proc):\n",
        "        p = mp.Process(target=train_model, args=(accuracies, indices, rank, n_feat, mutate_indices[counter]))\n",
        "        p.start()\n",
        "        processes.append(p)\n",
        "        counter += 1\n",
        "        if counter >= num_pop:\n",
        "          break\n",
        "      for p in processes:\n",
        "        p.join()\n",
        "    accuracies = list(accuracies)\n",
        "    indices = list(indices)\n",
        "    return np.asarray(accuracies), np.asarray(indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-Ag2AVlkVLC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a921055-ce0d-4a19-a40f-1febf491f9d5"
      },
      "source": [
        "accuracies, indices = train_initial_population(num_pop=300, num_proc=20, n_feat=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training initial population\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  7%|▋         | 1/15 [00:59<13:46, 59.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AProcess Process-534:\n",
            "Traceback (most recent call last):\n",
            "Process Process-539:\n",
            "Process Process-540:\n",
            "Process Process-535:\n",
            "Process Process-541:\n",
            "Process Process-536:\n",
            "Process Process-537:\n",
            "Process Process-542:\n",
            "Process Process-543:\n",
            "Process Process-538:\n",
            "Traceback (most recent call last):\n",
            "Process Process-544:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 46, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 46, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 46, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "ImportError: cannot import name 'notf'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 46, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 46, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "ImportError: cannot import name 'notf'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 46, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 46, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 46, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "ImportError: cannot import name 'notf'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 46, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "ImportError: cannot import name 'notf'\n",
            "ImportError: cannot import name 'notf'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 46, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "ImportError: cannot import name 'notf'\n",
            "ImportError: cannot import name 'notf'\n",
            "ImportError: cannot import name 'notf'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "ImportError: cannot import name 'notf'\n",
            "Traceback (most recent call last):\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "ImportError: cannot import name 'notf'\n",
            "Traceback (most recent call last):\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 46, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "ImportError: cannot import name 'notf'\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"<ipython-input-37-0155c50fe92e>\", line 32, in train_model\n",
            "    trainer.fit(model)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-37-0155c50fe92e>\", line 32, in train_model\n",
            "    trainer.fit(model)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-37-0155c50fe92e>\", line 32, in train_model\n",
            "    trainer.fit(model)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "Process Process-545:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\", line 470, in fit\n",
            "    results = self.accelerator_backend.train()\n",
            "  File \"<ipython-input-37-0155c50fe92e>\", line 32, in train_model\n",
            "    trainer.fit(model)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\", line 470, in fit\n",
            "    results = self.accelerator_backend.train()\n",
            "  File \"<ipython-input-37-0155c50fe92e>\", line 32, in train_model\n",
            "    trainer.fit(model)\n",
            "  File \"<ipython-input-37-0155c50fe92e>\", line 32, in train_model\n",
            "    trainer.fit(model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/cpu_accelerator.py\", line 59, in train\n",
            "    self.trainer.train_loop.setup_training(model)\n",
            "  File \"<ipython-input-37-0155c50fe92e>\", line 32, in train_model\n",
            "    trainer.fit(model)\n",
            "  File \"<ipython-input-37-0155c50fe92e>\", line 32, in train_model\n",
            "    trainer.fit(model)\n",
            "  File \"<ipython-input-37-0155c50fe92e>\", line 32, in train_model\n",
            "    trainer.fit(model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\", line 470, in fit\n",
            "    results = self.accelerator_backend.train()\n",
            "  File \"<ipython-input-37-0155c50fe92e>\", line 32, in train_model\n",
            "    trainer.fit(model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\", line 470, in fit\n",
            "    results = self.accelerator_backend.train()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\", line 470, in fit\n",
            "    results = self.accelerator_backend.train()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/cpu_accelerator.py\", line 59, in train\n",
            "    self.trainer.train_loop.setup_training(model)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\", line 470, in fit\n",
            "    results = self.accelerator_backend.train()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\", line 470, in fit\n",
            "    results = self.accelerator_backend.train()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\", line 470, in fit\n",
            "    results = self.accelerator_backend.train()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 145, in setup_training\n",
            "    self.trainer.logger.log_hyperparams(ref_model.hparams_initial)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\", line 470, in fit\n",
            "    results = self.accelerator_backend.train()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/cpu_accelerator.py\", line 59, in train\n",
            "    self.trainer.train_loop.setup_training(model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/cpu_accelerator.py\", line 59, in train\n",
            "    self.trainer.train_loop.setup_training(model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\", line 470, in fit\n",
            "    results = self.accelerator_backend.train()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/cpu_accelerator.py\", line 59, in train\n",
            "    self.trainer.train_loop.setup_training(model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 145, in setup_training\n",
            "    self.trainer.logger.log_hyperparams(ref_model.hparams_initial)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/cpu_accelerator.py\", line 59, in train\n",
            "    self.trainer.train_loop.setup_training(model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/cpu_accelerator.py\", line 59, in train\n",
            "    self.trainer.train_loop.setup_training(model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/cpu_accelerator.py\", line 59, in train\n",
            "    self.trainer.train_loop.setup_training(model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/cpu_accelerator.py\", line 59, in train\n",
            "    self.trainer.train_loop.setup_training(model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/cpu_accelerator.py\", line 59, in train\n",
            "    self.trainer.train_loop.setup_training(model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 145, in setup_training\n",
            "    self.trainer.logger.log_hyperparams(ref_model.hparams_initial)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 145, in setup_training\n",
            "    self.trainer.logger.log_hyperparams(ref_model.hparams_initial)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 145, in setup_training\n",
            "    self.trainer.logger.log_hyperparams(ref_model.hparams_initial)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"<ipython-input-37-0155c50fe92e>\", line 32, in train_model\n",
            "    trainer.fit(model)\n",
            "Process Process-546:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 46, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 145, in setup_training\n",
            "    self.trainer.logger.log_hyperparams(ref_model.hparams_initial)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 145, in setup_training\n",
            "    self.trainer.logger.log_hyperparams(ref_model.hparams_initial)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 168, in log_hyperparams\n",
            "    self.log_metrics(metrics, 0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 145, in setup_training\n",
            "    self.trainer.logger.log_hyperparams(ref_model.hparams_initial)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 145, in setup_training\n",
            "    self.trainer.logger.log_hyperparams(ref_model.hparams_initial)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 145, in setup_training\n",
            "    self.trainer.logger.log_hyperparams(ref_model.hparams_initial)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 168, in log_hyperparams\n",
            "    self.log_metrics(metrics, 0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\", line 470, in fit\n",
            "    results = self.accelerator_backend.train()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "ImportError: cannot import name 'notf'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 168, in log_hyperparams\n",
            "    self.log_metrics(metrics, 0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 168, in log_hyperparams\n",
            "    self.log_metrics(metrics, 0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/cpu_accelerator.py\", line 59, in train\n",
            "    self.trainer.train_loop.setup_training(model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 168, in log_hyperparams\n",
            "    self.log_metrics(metrics, 0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 168, in log_hyperparams\n",
            "    self.log_metrics(metrics, 0)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 168, in log_hyperparams\n",
            "    self.log_metrics(metrics, 0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 189, in log_metrics\n",
            "    self.experiment.add_scalar(k, v, step)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 168, in log_hyperparams\n",
            "    self.log_metrics(metrics, 0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 168, in log_hyperparams\n",
            "    self.log_metrics(metrics, 0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 168, in log_hyperparams\n",
            "    self.log_metrics(metrics, 0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 145, in setup_training\n",
            "    self.trainer.logger.log_hyperparams(ref_model.hparams_initial)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 46, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 39, in experiment\n",
            "    return get_experiment() or DummyExperiment()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 189, in log_metrics\n",
            "    self.experiment.add_scalar(k, v, step)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 189, in log_metrics\n",
            "    self.experiment.add_scalar(k, v, step)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 189, in log_metrics\n",
            "    self.experiment.add_scalar(k, v, step)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 39, in experiment\n",
            "    return get_experiment() or DummyExperiment()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 189, in log_metrics\n",
            "    self.experiment.add_scalar(k, v, step)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 189, in log_metrics\n",
            "    self.experiment.add_scalar(k, v, step)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "ImportError: cannot import name 'notf'\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 189, in log_metrics\n",
            "    self.experiment.add_scalar(k, v, step)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 189, in log_metrics\n",
            "    self.experiment.add_scalar(k, v, step)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 189, in log_metrics\n",
            "    self.experiment.add_scalar(k, v, step)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 39, in experiment\n",
            "    return get_experiment() or DummyExperiment()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 189, in log_metrics\n",
            "    self.experiment.add_scalar(k, v, step)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 38, in get_experiment\n",
            "    return fn(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 39, in experiment\n",
            "    return get_experiment() or DummyExperiment()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 39, in experiment\n",
            "    return get_experiment() or DummyExperiment()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 168, in log_hyperparams\n",
            "    self.log_metrics(metrics, 0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 39, in experiment\n",
            "    return get_experiment() or DummyExperiment()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 39, in experiment\n",
            "    return get_experiment() or DummyExperiment()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 39, in experiment\n",
            "    return get_experiment() or DummyExperiment()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 39, in experiment\n",
            "    return get_experiment() or DummyExperiment()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 143, in experiment\n",
            "    self._experiment = SummaryWriter(log_dir=self.log_dir, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 39, in experiment\n",
            "    return get_experiment() or DummyExperiment()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 38, in get_experiment\n",
            "    return fn(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"<ipython-input-37-0155c50fe92e>\", line 32, in train_model\n",
            "    trainer.fit(model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "Traceback (most recent call last):\n",
            "Process Process-547:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 189, in log_metrics\n",
            "    self.experiment.add_scalar(k, v, step)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 38, in get_experiment\n",
            "    return fn(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 221, in __init__\n",
            "    self._get_file_writer()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 38, in get_experiment\n",
            "    return fn(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 38, in get_experiment\n",
            "    return fn(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 143, in experiment\n",
            "    self._experiment = SummaryWriter(log_dir=self.log_dir, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 38, in get_experiment\n",
            "    return fn(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 38, in get_experiment\n",
            "    return fn(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 38, in get_experiment\n",
            "    return fn(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 39, in experiment\n",
            "    return get_experiment() or DummyExperiment()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 38, in get_experiment\n",
            "    return fn(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 143, in experiment\n",
            "    self._experiment = SummaryWriter(log_dir=self.log_dir, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\", line 470, in fit\n",
            "    results = self.accelerator_backend.train()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 143, in experiment\n",
            "    self._experiment = SummaryWriter(log_dir=self.log_dir, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 221, in __init__\n",
            "    self._get_file_writer()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 38, in get_experiment\n",
            "    return fn(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 252, in _get_file_writer\n",
            "    self.flush_secs, self.filename_suffix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 143, in experiment\n",
            "    self._experiment = SummaryWriter(log_dir=self.log_dir, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 143, in experiment\n",
            "    self._experiment = SummaryWriter(log_dir=self.log_dir, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 143, in experiment\n",
            "    self._experiment = SummaryWriter(log_dir=self.log_dir, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/cpu_accelerator.py\", line 59, in train\n",
            "    self.trainer.train_loop.setup_training(model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 143, in experiment\n",
            "    self._experiment = SummaryWriter(log_dir=self.log_dir, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 221, in __init__\n",
            "    self._get_file_writer()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 143, in experiment\n",
            "    self._experiment = SummaryWriter(log_dir=self.log_dir, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 221, in __init__\n",
            "    self._get_file_writer()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-8b158028e6db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_initial_population\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_pop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_feat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-312287ecc235>\u001b[0m in \u001b[0;36mtrain_initial_population\u001b[0;34m(num_pop, num_proc, n_feat)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprocesses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 62, in __init__\n",
            "    log_dir, max_queue, flush_secs, filename_suffix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 38, in get_experiment\n",
            "    return fn(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 221, in __init__\n",
            "    self._get_file_writer()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 221, in __init__\n",
            "    self._get_file_writer()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 221, in __init__\n",
            "    self._get_file_writer()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 143, in experiment\n",
            "    self._experiment = SummaryWriter(log_dir=self.log_dir, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 221, in __init__\n",
            "    self._get_file_writer()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 252, in _get_file_writer\n",
            "    self.flush_secs, self.filename_suffix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 145, in setup_training\n",
            "    self.trainer.logger.log_hyperparams(ref_model.hparams_initial)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 252, in _get_file_writer\n",
            "    self.flush_secs, self.filename_suffix)\n",
            "  File \"<ipython-input-37-0155c50fe92e>\", line 32, in train_model\n",
            "    trainer.fit(model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 221, in __init__\n",
            "    self._get_file_writer()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 46, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 252, in _get_file_writer\n",
            "    self.flush_secs, self.filename_suffix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 76, in __init__\n",
            "    if not tf.io.gfile.exists(logdir):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 252, in _get_file_writer\n",
            "    self.flush_secs, self.filename_suffix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 143, in experiment\n",
            "    self._experiment = SummaryWriter(log_dir=self.log_dir, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 221, in __init__\n",
            "    self._get_file_writer()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 62, in __init__\n",
            "    log_dir, max_queue, flush_secs, filename_suffix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 62, in __init__\n",
            "    log_dir, max_queue, flush_secs, filename_suffix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 62, in __init__\n",
            "    log_dir, max_queue, flush_secs, filename_suffix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 252, in _get_file_writer\n",
            "    self.flush_secs, self.filename_suffix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 252, in _get_file_writer\n",
            "    self.flush_secs, self.filename_suffix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 252, in _get_file_writer\n",
            "    self.flush_secs, self.filename_suffix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 252, in _get_file_writer\n",
            "    self.flush_secs, self.filename_suffix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\", line 470, in fit\n",
            "    results = self.accelerator_backend.train()\n",
            "ImportError: cannot import name 'notf'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 62, in __init__\n",
            "    log_dir, max_queue, flush_secs, filename_suffix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 252, in _get_file_writer\n",
            "    self.flush_secs, self.filename_suffix)\n",
            "Process Process-548:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 76, in __init__\n",
            "    if not tf.io.gfile.exists(logdir):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 68, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 221, in __init__\n",
            "    self._get_file_writer()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 76, in __init__\n",
            "    if not tf.io.gfile.exists(logdir):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 168, in log_hyperparams\n",
            "    self.log_metrics(metrics, 0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 76, in __init__\n",
            "    if not tf.io.gfile.exists(logdir):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 62, in __init__\n",
            "    log_dir, max_queue, flush_secs, filename_suffix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 62, in __init__\n",
            "    log_dir, max_queue, flush_secs, filename_suffix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 62, in __init__\n",
            "    log_dir, max_queue, flush_secs, filename_suffix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 62, in __init__\n",
            "    log_dir, max_queue, flush_secs, filename_suffix)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 252, in _get_file_writer\n",
            "    self.flush_secs, self.filename_suffix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 68, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 100, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 68, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/cpu_accelerator.py\", line 59, in train\n",
            "    self.trainer.train_loop.setup_training(model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 76, in __init__\n",
            "    if not tf.io.gfile.exists(logdir):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 62, in __init__\n",
            "    log_dir, max_queue, flush_secs, filename_suffix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 68, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 76, in __init__\n",
            "    if not tf.io.gfile.exists(logdir):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 76, in __init__\n",
            "    if not tf.io.gfile.exists(logdir):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 53, in load_once\n",
            "    module = load_fn()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 62, in __init__\n",
            "    log_dir, max_queue, flush_secs, filename_suffix)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 76, in __init__\n",
            "    if not tf.io.gfile.exists(logdir):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 100, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 100, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 76, in __init__\n",
            "    if not tf.io.gfile.exists(logdir):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 145, in setup_training\n",
            "    self.trainer.logger.log_hyperparams(ref_model.hparams_initial)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 68, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 189, in log_metrics\n",
            "    self.experiment.add_scalar(k, v, step)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 68, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 49, in tf\n",
            "    import tensorflow\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 76, in __init__\n",
            "    if not tf.io.gfile.exists(logdir):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 100, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 68, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "Process Process-549:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 76, in __init__\n",
            "    if not tf.io.gfile.exists(logdir):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 53, in load_once\n",
            "    module = load_fn()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 46, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 68, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 68, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 100, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 39, in experiment\n",
            "    return get_experiment() or DummyExperiment()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 68, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 100, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 41, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 53, in load_once\n",
            "    module = load_fn()\n",
            "ImportError: cannot import name 'notf'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 49, in tf\n",
            "    import tensorflow\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 53, in load_once\n",
            "    module = load_fn()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 100, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 68, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 100, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "Process Process-550:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 100, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 53, in load_once\n",
            "    module = load_fn()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 53, in load_once\n",
            "    module = load_fn()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/__init__.py\", line 41, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 100, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 49, in tf\n",
            "    import tensorflow\n",
            "  File \"<ipython-input-37-0155c50fe92e>\", line 32, in train_model\n",
            "    trainer.fit(model)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 168, in log_hyperparams\n",
            "    self.log_metrics(metrics, 0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 53, in load_once\n",
            "    module = load_fn()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 100, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 53, in load_once\n",
            "    module = load_fn()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 53, in load_once\n",
            "    module = load_fn()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 49, in tf\n",
            "    import tensorflow\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 41, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/base.py\", line 38, in get_experiment\n",
            "    return fn(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 49, in tf\n",
            "    import tensorflow\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 46, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\", line 39, in <module>\n",
            "    from tensorflow.python.eager import monitoring\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 53, in load_once\n",
            "    module = load_fn()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 49, in tf\n",
            "    import tensorflow\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py\", line 39, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\", line 470, in fit\n",
            "    results = self.accelerator_backend.train()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 41, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 49, in tf\n",
            "    import tensorflow\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\", line 53, in load_once\n",
            "    module = load_fn()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 49, in tf\n",
            "    import tensorflow\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 143, in experiment\n",
            "    self._experiment = SummaryWriter(log_dir=self.log_dir, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 49, in tf\n",
            "    import tensorflow\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/__init__.py\", line 41, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 41, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 41, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "ImportError: cannot import name 'notf'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 41, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/monitoring.py\", line 31, in <module>\n",
            "    _MetricMethod = collections.namedtuple('MetricMethod', 'create delete get_cell')\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 49, in tf\n",
            "    import tensorflow\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 189, in log_metrics\n",
            "    self.experiment.add_scalar(k, v, step)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/__init__.py\", line 41, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 41, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 41, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\", line 49, in tf\n",
            "    import tensorflow\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\", line 221, in __init__\n",
            "    self._get_file_writer()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/cpu_accelerator.py\", line 59, in train\n",
            "    self.trainer.train_loop.setup_training(model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 41, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/lib/python3.6/collections/__init__.py\", line 429, in namedtuple\n",
            "    exec(class_definition, namespace)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 41, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQJAbJ52f-04"
      },
      "source": [
        "#np.save('')\n",
        "#np.save(os.path.join(\"/content/gdrive/MyDrive/Data\", 'init_accuracies.npy'), accuracies)\n",
        "#np.save(os.path.join(\"/content/gdrive/MyDrive/Data\", 'init_indices.npy'), indices)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "dnqiomV2awlh",
        "outputId": "7b18de52-bef8-4384-d91a-9cae9b6e0e47"
      },
      "source": [
        "#max_accuracies = []\n",
        "#max_accuracies.append(np.max(accuracies))\n",
        "for i in tqdm(range(50)):\n",
        "  accuracies, indices, mutate_indices = mutate(accuracies, indices, mutate_freq=0.5, frac_to_kill=0.4)\n",
        "  accuracies, indices = train_mutations(mutate_indices, accuracies, indices, num_proc=50)\n",
        "  max_accuracies.append(np.max(accuracies))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-7eca6d854248>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#max_accuracies.append(np.max(accuracies))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutate_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutate_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrac_to_kill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_mutations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmutate_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mmax_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'accuracies' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "dv0RRmoBkt10",
        "outputId": "ae7ff460-dd99-4bda-9baa-466f5e6d4e95"
      },
      "source": [
        "plt.plot(max_accuracies)\n",
        "plt.title('Accuracies through Evolution')\n",
        "plt.xlabel()\n",
        "plt.ylabel()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff03698f240>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7yfzhrO9lRZ"
      },
      "source": [
        "#np.save('')\n",
        "'''\n",
        "np.save(os.path.join(\"/content/gdrive/MyDrive/Data\", 'curr_accuracies.npy'), accuracies)\n",
        "np.save(os.path.join(\"/content/gdrive/MyDrive/Data\", 'curr_indices.npy'), indices)\n",
        "np.save(os.path.join(\"/content/gdrive/MyDrive/Data\", 'max_accuracies.npy'), max_accuracies)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDYnSXqLvdNT"
      },
      "source": [
        "accuracies = np.load(os.path.join(\"/content/gdrive/MyDrive/Data\", 'curr_accuracies.npy'))\n",
        "indices = np.load(os.path.join(\"/content/gdrive/MyDrive/Data\", 'curr_indices.npy'))\n",
        "max_accuracies = np.load(os.path.join(\"/content/gdrive/MyDrive/Data\", 'max_accuracies.npy'))\n",
        "a = list(max_accuracies)\n",
        "a.insert(0, 0.41543513536453247)\n",
        "a.insert(0, 0.3776683211326599)\n",
        "a.insert(0, 0.3530377745628357)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZy66e80_gxb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "1a27252c-0b59-4738-c444-8759fc59dce4"
      },
      "source": [
        "plt.plot(max_accuracies)\n",
        "plt.title('Accuracies through Evolution')\n",
        "plt.xlabel('Round of evolution')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "sY56cSZqxW32",
        "outputId": "68997ea5-93cd-4d2e-995c-94b7e8e2d094"
      },
      "source": [
        "plt.plot(a)\n",
        "plt.title('Accuracies through Evolution')\n",
        "plt.xlabel('Round of evolution')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdoyXrN-x29A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}